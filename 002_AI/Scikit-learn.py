# -*- coding: utf-8 -*-
"""
ğŸ¤– ULTIMATE SCIKIT-LEARN CHEAT SHEET
Author: Báº¡n ğŸ˜ | Dá»±a trÃªn scikit-learn 1.4+
Cháº¡y toÃ n bá»™ script Ä‘á»ƒ xem vÃ­ dá»¥ minh há»a!
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn import datasets, preprocessing, model_selection, metrics
from sklearn import linear_model, svm, tree, ensemble, cluster, decomposition
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
import joblib

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1ï¸âƒ£ Táº¢I Dá»® LIá»†U MáºªU
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("1ï¸âƒ£ Táº¢I Dá»® LIá»†U")
# Bá»™ dá»¯ liá»‡u phÃ¢n loáº¡i (Iris)
X_cls, y_cls = datasets.load_iris(return_X_y=True)
# Bá»™ dá»¯ liá»‡u há»“i quy (Boston bá»‹ gá»¡ â†’ dÃ¹ng California Housing)
X_reg, y_reg = datasets.fetch_california_housing(return_X_y=True)
# Dá»¯ liá»‡u khÃ´ng giÃ¡m sÃ¡t (digits Ä‘á»ƒ clustering)
X_unsup = datasets.load_digits().data

print("PhÃ¢n loáº¡i: X shape =", X_cls.shape)
print("Há»“i quy: X shape =", X_reg.shape)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2ï¸âƒ£ CHIA Dá»® LIá»†U (Train/Test)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("\n2ï¸âƒ£ CHIA Dá»® LIá»†U")
X_train, X_test, y_train, y_test = model_selection.train_test_split(
    X_cls, y_cls, test_size=0.2, random_state=42, stratify=y_cls
)
print("Train size:", X_train.shape[0], "| Test size:", X_test.shape[0])

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3ï¸âƒ£ TIá»€N Xá»¬ LÃ Dá»® LIá»†U
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("\n3ï¸âƒ£ TIá»€N Xá»¬ LÃ")
# Chuáº©n hÃ³a (StandardScaler)
scaler = preprocessing.StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# MÃ£ hÃ³a nhÃ£n (náº¿u cáº§n)
label_enc = preprocessing.LabelEncoder()
# y_encoded = label_enc.fit_transform(y_categorical)

# One-hot encoding (dÃ nh cho dá»¯ liá»‡u phÃ¢n loáº¡i trong DataFrame)
# df = pd.DataFrame(X_cls, columns=['sepal_l', 'sepal_w', 'petal_l', 'petal_w'])
# preprocessor = ColumnTransformer(
#     transformers=[('num', preprocessing.StandardScaler(), numerical_cols)],
#     remainder='passthrough'
# )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4ï¸âƒ£ HUáº¤N LUYá»†N MÃ” HÃŒNH PHÃ‚N LOáº I
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("\n4ï¸âƒ£ PHÃ‚N LOáº I")
models = {
    "LogisticRegression": linear_model.LogisticRegression(max_iter=200),
    "SVM": svm.SVC(),
    "RandomForest": ensemble.RandomForestClassifier(random_state=42)
}

for name, model in models.items():
    model.fit(X_train_scaled, y_train)
    acc = model.score(X_test_scaled, y_test)
    print(f"{name}: Accuracy = {acc:.3f}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 5ï¸âƒ£ HUáº¤N LUYá»†N MÃ” HÃŒNH Há»’I QUY
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("\n5ï¸âƒ£ Há»’I QUY")
Xr_train, Xr_test, yr_train, yr_test = model_selection.train_test_split(
    X_reg, y_reg, test_size=0.2, random_state=42
)
scaler_r = preprocessing.StandardScaler()
Xr_train_scaled = scaler_r.fit_transform(Xr_train)
Xr_test_scaled = scaler_r.transform(Xr_test)

reg_models = {
    "Linear": linear_model.LinearRegression(),
    "Ridge": linear_model.Ridge(alpha=1.0),
    "RandomForest": ensemble.RandomForestRegressor(random_state=42)
}

for name, model in reg_models.items():
    model.fit(Xr_train_scaled, yr_train)
    r2 = model.score(Xr_test_scaled, yr_test)
    print(f"{name}: RÂ² = {r2:.3f}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 6ï¸âƒ£ ÄÃNH GIÃ MÃ” HÃŒNH
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("\n6ï¸âƒ£ ÄÃNH GIÃ")
best_model = models["RandomForest"]
y_pred = best_model.predict(X_test_scaled)

# PhÃ¢n loáº¡i
print("Accuracy:", metrics.accuracy_score(y_test, y_pred))
print("Classification Report:\n", metrics.classification_report(y_test, y_pred))
print("Confusion Matrix:\n", metrics.confusion_matrix(y_test, y_pred))

# Há»“i quy (dÃ¹ng mÃ´ hÃ¬nh há»“i quy)
y_pred_reg = reg_models["Ridge"].predict(Xr_test_scaled)
print("MAE:", metrics.mean_absolute_error(yr_test, y_pred_reg))
print("MSE:", metrics.mean_squared_error(yr_test, y_pred_reg))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 7ï¸âƒ£ CROSS-VALIDATION
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("\n7ï¸âƒ£ CROSS-VALIDATION")
from sklearn.model_selection import cross_val_score
scores = cross_val_score(models["SVM"], X_train_scaled, y_train, cv=5)
print("CV Accuracy:", scores.mean(), "Â±", scores.std())

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 8ï¸âƒ£ TINH CHá»ˆNH SIÃŠU THAM Sá» (Hyperparameter Tuning)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("\n8ï¸âƒ£ TINH CHá»ˆNH SIÃŠU THAM Sá»")
from sklearn.model_selection import GridSearchCV

param_grid = {
    'C': [0.1, 1, 10],
    'kernel': ['linear', 'rbf']
}
grid = GridSearchCV(svm.SVC(), param_grid, cv=3, scoring='accuracy')
grid.fit(X_train_scaled, y_train)
print("Best params:", grid.best_params_)
print("Best CV score:", grid.best_score_)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 9ï¸âƒ£ Há»ŒC KHÃ”NG GIÃM SÃT: CLUSTERING
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("\n9ï¸âƒ£ CLUSTERING")
kmeans = cluster.KMeans(n_clusters=3, random_state=42)
clusters = kmeans.fit_predict(X_unsup[:100])  # chá»‰ 100 máº«u Ä‘á»ƒ nhanh
print("Sá»‘ cá»¥m:", len(np.unique(clusters)))

# ÄÃ¡nh giÃ¡ (náº¿u cÃ³ nhÃ£n tháº­t)
# from sklearn.metrics import adjusted_rand_score
# ari = adjusted_rand_score(true_labels, clusters)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ”Ÿ GIáº¢M CHIá»€U Dá»® LIá»†U (PCA)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("\nğŸ”Ÿ PCA")
pca = decomposition.PCA(n_components=2)
X_pca = pca.fit_transform(X_unsup[:100])
print("Giáº£i thÃ­ch phÆ°Æ¡ng sai:", pca.explained_variance_ratio_.sum())

# Váº½ (náº¿u cáº§n)
# plt.scatter(X_pca[:, 0], X_pca[:, 1], c=clusters, cmap='tab10')
# plt.title("PCA + KMeans")
# plt.show()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1ï¸âƒ£1ï¸âƒ£ PIPELINE Tá»° Äá»˜NG
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("\n1ï¸âƒ£1ï¸âƒ£ PIPELINE")
pipe = Pipeline([
    ('scaler', preprocessing.StandardScaler()),
    ('clf', ensemble.RandomForestClassifier(random_state=42))
])
pipe.fit(X_train, y_train)
print("Pipeline accuracy:", pipe.score(X_test, y_test))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1ï¸âƒ£2ï¸âƒ£ LÆ¯U & Táº¢I MÃ” HÃŒNH
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("\n1ï¸âƒ£2ï¸âƒ£ LÆ¯U/Táº¢I MÃ” HÃŒNH")
joblib.dump(pipe, "model.pkl")
loaded_model = joblib.load("model.pkl")
print("MÃ´ hÃ¬nh táº£i láº¡i hoáº¡t Ä‘á»™ng:", loaded_model.score(X_test, y_test))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# âœ… Káº¾T THÃšC
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("\nğŸ‰ XONG! ÄÃ¢y lÃ  Ultimate Scikit-learn Cheat Sheet.")
print("ğŸ’¡ Gá»£i Ã½: DÃ¹ng trong Jupyter Notebook Ä‘á»ƒ káº¿t há»£p vá»›i matplotlib!")