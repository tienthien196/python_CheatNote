{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a9105a1",
   "metadata": {},
   "source": [
    "🔹 1. Nguyên lý hoạt động (không công thức nặng!)\n",
    "🎯 Mục tiêu:\n",
    "Cải thiện Decision Tree đơn lẻ bằng cách kết hợp nhiều cây để:\n",
    "\n",
    "Giảm overfitting\n",
    "Tăng độ chính xác\n",
    "Làm mô hình ổn định hơn\n",
    "🧠 Ý tưởng chính — “Nhiều cái đầu hơn một cái đầu!”\n",
    "Random Forest = Rừng gồm nhiều Decision Tree, mỗi cây được huấn luyện khác nhau một cách ngẫu nhiên, và dự đoán cuối cùng là đa số phiếu. \n",
    "\n",
    "🔍 Hai yếu tố \"ngẫu nhiên\" cốt lõi:\n",
    "Bootstrap sampling (Bagging):\n",
    "Mỗi cây được huấn luyện trên một tập con ngẫu nhiên có hoàn lại từ dữ liệu gốc.\n",
    "Ví dụ: Dữ liệu có 100 mẫu → mỗi cây dùng ~63 mẫu (có lặp).\n",
    "Random feature selection:\n",
    "Khi chia một nút, chỉ xét một tập con ngẫu nhiên các đặc trưng (thay vì tất cả).\n",
    "Ví dụ: Có 10 đặc trưng → mỗi lần chia chỉ xem 3 đặc trưng ngẫu nhiên.\n",
    "→ Nhờ đó, các cây trong rừng khác nhau, không học cùng một lỗi, nên kết hợp lại sẽ tốt hơn.\n",
    "\n",
    "💡 Dự đoán như thế nào?\n",
    "Phân loại: Mỗi cây đưa ra một dự đoán → lớp được nhiều cây chọn nhất thắng (voting).\n",
    "Hồi quy: Trung bình giá trị dự đoán của tất cả cây.\n",
    "✅ Ưu điểm:\n",
    "Rất khó overfit (ngay cả khi cây rất sâu).\n",
    "Không cần chuẩn hóa dữ liệu.\n",
    "Xử lý tốt đặc trưng không quan trọng (tự động giảm ảnh hưởng).\n",
    "Cho điểm quan trọng của đặc trưng (feature importance).\n",
    "Hiệu suất cao, dễ dùng, ít tinh chỉnh.\n",
    "❌ Hạn chế:\n",
    "Ít trực quan hơn Decision Tree đơn (vì là tập hợp nhiều cây).\n",
    "Dự đoán chậm hơn một cây đơn (nhưng vẫn nhanh hơn KNN!).\n",
    "Không ngoại suy tốt (giống Decision Tree).\n",
    "\n",
    "\n",
    "🔹 3. Khi nào dùng Random Forest?\n",
    "Bạn cần\n",
    "mô hình mạnh, ít tinh chỉnh\n",
    ", cho kết quả tốt ngay lập tức\n",
    "Cần\n",
    "giải thích chi tiết từng quyết định\n",
    "(dùng Decision Tree thay vì RF)\n",
    "Dữ liệu\n",
    "hỗn hợp\n",
    ", có nhiễu, có đặc trưng không quan trọng\n",
    "Bài toán\n",
    "rất lớn\n",
    "(triệu mẫu) → hãy cân nhắc\n",
    "XGBoost/LightGBM\n",
    "(nhanh hơn)\n",
    "Muốn\n",
    "đánh giá đặc trưng nào quan trọng\n",
    "Cần\n",
    "xác suất đầu ra rất chính xác\n",
    "(RF đôi khi cho xác suất bị lệch)\n",
    "Làm\n",
    "baseline mạnh\n",
    "cho hầu hết bài toán có giám sát\n",
    "Dữ liệu\n",
    "chuỗi thời gian\n",
    "có tính thứ tự → RF không tận dụng được"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e51a44c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SimpleDecisionTree' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 70\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# Huấn luyện mô hình tự code\u001b[39;00m\n\u001b[0;32m     69\u001b[0m rf_model \u001b[38;5;241m=\u001b[39m SimpleRandomForest(n_trees\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m---> 70\u001b[0m \u001b[43mrf_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m rf_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     73\u001b[0m acc \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred)\n",
      "Cell \u001b[1;32mIn[1], line 26\u001b[0m, in \u001b[0;36mSimpleRandomForest.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39msqrt(n_features))\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_trees):\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;66;03m# Tạo cây mới\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m     tree \u001b[38;5;241m=\u001b[39m \u001b[43mSimpleDecisionTree\u001b[49m(\n\u001b[0;32m     27\u001b[0m         max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth,\n\u001b[0;32m     28\u001b[0m         min_samples_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_samples_split\n\u001b[0;32m     29\u001b[0m     )\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;66;03m# Lấy mẫu bootstrap\u001b[39;00m\n\u001b[0;32m     32\u001b[0m     X_boot, y_boot \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bootstrap_sample(X, y)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SimpleDecisionTree' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class SimpleRandomForest:\n",
    "    def __init__(self, n_trees=10, max_depth=5, min_samples_split=2, max_features=None):\n",
    "        self.n_trees = n_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_features = max_features  # số đặc trưng ngẫu nhiên mỗi lần chia\n",
    "        self.trees = []\n",
    "\n",
    "    def _bootstrap_sample(self, X, y):\n",
    "        \"\"\"Lấy mẫu ngẫu nhiên có hoàn lại (bootstrap)\"\"\"\n",
    "        n_samples = X.shape[0]\n",
    "        idxs = np.random.choice(n_samples, size=n_samples, replace=True)\n",
    "        return X[idxs], y[idxs]\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.trees = []\n",
    "        n_features = X.shape[1]\n",
    "        # Nếu không chỉ định, mặc định dùng sqrt(n_features) cho phân loại\n",
    "        if self.max_features is None:\n",
    "            self.max_features = int(np.sqrt(n_features))\n",
    "\n",
    "        for _ in range(self.n_trees):\n",
    "            # Tạo cây mới\n",
    "            tree = SimpleDecisionTree(\n",
    "                max_depth=self.max_depth,\n",
    "                min_samples_split=self.min_samples_split\n",
    "            )\n",
    "            \n",
    "            # Lấy mẫu bootstrap\n",
    "            X_boot, y_boot = self._bootstrap_sample(X, y)\n",
    "            \n",
    "            # Huấn luyện cây (trong phiên bản đầy đủ, bạn sẽ chọn ngẫu nhiên đặc trưng trong _best_split)\n",
    "            # Ở đây, để đơn giản, ta giả lập bằng cách **giới hạn đặc trưng ngẫu nhiên toàn cây**\n",
    "            # (thực tế, sklearn chọn ngẫu nhiên **mỗi lần chia**)\n",
    "            feature_subset = np.random.choice(n_features, size=self.max_features, replace=False)\n",
    "            X_boot_subset = X_boot[:, feature_subset]\n",
    "            \n",
    "            tree.fit(X_boot_subset, y_boot)\n",
    "            self.trees.append((tree, feature_subset))  # lưu cả cây và đặc trưng đã dùng\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Dự đoán từ từng cây\n",
    "        tree_preds = []\n",
    "        for tree, features in self.trees:\n",
    "            X_subset = X[:, features]\n",
    "            preds = tree.predict(X_subset)\n",
    "            tree_preds.append(preds)\n",
    "        \n",
    "        # Voting: chọn lớp xuất hiện nhiều nhất\n",
    "        tree_preds = np.array(tree_preds).T  # shape: (n_samples, n_trees)\n",
    "        predictions = []\n",
    "        for pred_row in tree_preds:\n",
    "            most_common = np.bincount(pred_row).argmax()\n",
    "            predictions.append(most_common)\n",
    "        return np.array(predictions)\n",
    "\n",
    "# --- Thử nghiệm ---\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Huấn luyện mô hình tự code\n",
    "rf_model = SimpleRandomForest(n_trees=10, max_depth=4)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"✅ Độ chính xác (Random Forest tự code): {acc:.2%}\")\n",
    "\n",
    "# So sánh với sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "sk_rf = RandomForestClassifier(n_estimators=10, max_depth=4, random_state=42)\n",
    "sk_rf.fit(X_train, y_train)\n",
    "sk_acc = sk_rf.score(X_test, y_test)\n",
    "print(f\"🔍 Sklearn RandomForest độ chính xác: {sk_acc:.2%}\")\n",
    "\n",
    "# Xem feature importance từ sklearn\n",
    "print(\"\\n🌟 Feature importance (từ sklearn):\")\n",
    "for name, imp in zip(iris.feature_names, sk_rf.feature_importances_):\n",
    "    print(f\"  {name}: {imp:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
