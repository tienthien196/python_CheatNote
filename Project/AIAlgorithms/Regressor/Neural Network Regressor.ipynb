{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "983541e9",
   "metadata": {},
   "source": [
    "â€” tá»©c lÃ  sá»­ dá»¥ng máº¡ng neural (Neural Networks) Ä‘á»ƒ dá»± Ä‘oÃ¡n giÃ¡ trá»‹ liÃªn tá»¥c, thay vÃ¬ phÃ¢n loáº¡i.\n",
    "\n",
    "ÄÃ¢y lÃ  bÆ°á»›c má»Ÿ Ä‘Æ°á»ng vÃ o Deep Learning cho há»“i quy, vÃ  cá»±c ká»³ quan trá»ng trong cÃ¡c bÃ i toÃ¡n nhÆ°: dá»± bÃ¡o thá»i tiáº¿t, dá»± Ä‘oÃ¡n giÃ¡ cá»• phiáº¿u, Æ°á»›c lÆ°á»£ng nÄƒng lÆ°á»£ng tiÃªu thá»¥, v.v.\n",
    "\n",
    "MÃ¬nh sáº½ trÃ¬nh bÃ y theo Ä‘Ãºng phong cÃ¡ch báº¡n yÃªu thÃ­ch:\n",
    "\n",
    "ğŸ”¹ 1. NguyÃªn lÃ½ hoáº¡t Ä‘á»™ng (khÃ´ng cÃ´ng thá»©c náº·ng!)\n",
    "ğŸ¯ Má»¥c tiÃªu:\n",
    "Dá»± Ä‘oÃ¡n má»™t sá»‘ thá»±c (giÃ¡ nhÃ , nhiá»‡t Ä‘á»™, doanh thu...) báº±ng cÃ¡ch há»c biá»ƒu diá»…n phi tuyáº¿n phá»©c táº¡p tá»« dá»¯ liá»‡u, thÃ´ng qua nhiá»u lá»›p nÆ¡-ron nhÃ¢n táº¡o.\n",
    "\n",
    "ğŸ§  Ã tÆ°á»Ÿng chÃ­nh â€” â€œHá»c tá»« Ä‘Æ¡n giáº£n Ä‘áº¿n phá»©c táº¡p, rá»“i Ä‘Æ°a ra con sá»‘â€\n",
    "Äáº§u vÃ o: cÃ¡c Ä‘áº·c trÆ°ng (diá»‡n tÃ­ch, sá»‘ phÃ²ng, vá»‹ trÃ­â€¦)\n",
    "CÃ¡c lá»›p áº©n: há»c Ä‘áº·c trÆ°ng ngÃ y cÃ ng trá»«u tÆ°á»£ng\n",
    "Lá»›p 1: káº¿t há»£p tuyáº¿n tÃ­nh â†’ Ã¡p hÃ m kÃ­ch hoáº¡t (ReLU)\n",
    "Lá»›p 2: káº¿t há»£p káº¿t quáº£ lá»›p 1 â†’ láº¡i Ã¡p ReLU\n",
    "...\n",
    "Äáº§u ra: má»™t nÆ¡-ron duy nháº¥t, khÃ´ng cÃ³ hÃ m kÃ­ch hoáº¡t phi tuyáº¿n (hoáº·c dÃ¹ng hÃ m identity) â†’ ra giÃ¡ trá»‹ thá»±c\n",
    "ğŸ’¡ KhÃ¡c vá»›i phÃ¢n loáº¡i (dÃ¹ng softmax/sigmoid Ä‘á»ƒ ra xÃ¡c suáº¥t),\n",
    "há»“i quy báº±ng máº¡ng neural â†’ lá»›p cuá»‘i cÃ¹ng lÃ  tuyáº¿n tÃ­nh. \n",
    "\n",
    "ğŸ” QuÃ¡ trÃ¬nh há»c:\n",
    "Forward pass: Ä‘Æ°a dá»¯ liá»‡u qua máº¡ng â†’ ra dá»± Ä‘oÃ¡n sá»‘ thá»±c.\n",
    "TÃ­nh lá»—i: thÆ°á»ng dÃ¹ng MSE (Mean Squared Error).\n",
    "Backpropagation: lan truyá»n lá»—i ngÆ°á»£c â†’ cáº­p nháº­t trá»ng sá»‘.\n",
    "Láº·p láº¡i â†’ máº¡ng ngÃ y cÃ ng dá»± Ä‘oÃ¡n chÃ­nh xÃ¡c hÆ¡n.\n",
    "âœ… Æ¯u Ä‘iá»ƒm:\n",
    "Máº¡nh vá»›i quan há»‡ phi tuyáº¿n phá»©c táº¡p.\n",
    "Tá»± Ä‘á»™ng há»c Ä‘áº·c trÆ°ng â€” khÃ´ng cáº§n thiáº¿t káº¿ tay.\n",
    "Má»Ÿ rá»™ng tá»‘t: cÃ³ thá»ƒ thÃªm lá»›p, nÆ¡-ron, hoáº·c chuyá»ƒn sang CNN/RNN náº¿u cáº§n.\n",
    "âŒ Háº¡n cháº¿:\n",
    "Cáº§n nhiá»u dá»¯ liá»‡u Ä‘á»ƒ há»c tá»‘t.\n",
    "Tá»‘n tÃ i nguyÃªn (GPU, thá»i gian huáº¥n luyá»‡n).\n",
    "Dá»… overfit náº¿u khÃ´ng kiá»ƒm soÃ¡t (dÃ¹ng dropout, early stoppingâ€¦).\n",
    "â€œHá»™p Ä‘enâ€: khÃ³ giáº£i thÃ­ch táº¡i sao ra con sá»‘ Ä‘Ã³.\n",
    "\n",
    "\n",
    "ğŸ”¹ 3. Khi nÃ o dÃ¹ng Neural Network Regressor?\n",
    "Dá»¯ liá»‡u\n",
    "ráº¥t lá»›n\n",
    "(hÃ ng chá»¥c nghÃ¬n máº«u trá»Ÿ lÃªn)\n",
    "Dá»¯ liá»‡u\n",
    "nhá»\n",
    "(< 1000 máº«u) â†’ dÃ¹ng\n",
    "Random Forest\n",
    "hoáº·c\n",
    "SVR\n",
    "Má»‘i quan há»‡\n",
    "phi tuyáº¿n cá»±c ká»³ phá»©c táº¡p\n",
    "Má»‘i quan há»‡\n",
    "gáº§n tuyáº¿n tÃ­nh\n",
    "â†’ Linear/Ridge/Lasso Ä‘á»§\n",
    "Báº¡n cÃ³\n",
    "GPU\n",
    "vÃ \n",
    "thá»i gian huáº¥n luyá»‡n\n",
    "Cáº§n\n",
    "káº¿t quáº£ nhanh, Ä‘Æ¡n giáº£n\n",
    "BÃ i toÃ¡n\n",
    "áº£nh, chuá»—i, vÄƒn báº£n\n",
    "(khi má»Ÿ rá»™ng thÃ nh CNN/RNN)\n",
    "Dá»¯ liá»‡u\n",
    "báº£ng Ä‘Æ¡n giáº£n\n",
    "(Excel-style) â†’ RF thÆ°á»ng Ä‘á»§ vÃ  giáº£i thÃ­ch Ä‘Æ°á»£c\n",
    "\n",
    "ğŸ¯ So sÃ¡nh nhanh vá»›i cÃ¡c mÃ´ hÃ¬nh há»“i quy khÃ¡c:\n",
    "Linear/Ridge/Lasso\n",
    "âœ… Tá»‘t\n",
    "âœ… Tá»‘t\n",
    "âŒ KÃ©m\n",
    "âœ… Ráº¥t tá»‘t\n",
    "âš¡ Ráº¥t nhanh\n",
    "Decision Tree\n",
    "âœ… Tá»‘t\n",
    "âœ… Tá»‘t\n",
    "âœ… Tá»‘t\n",
    "âœ… Tá»‘t\n",
    "âš¡ Nhanh\n",
    "Random Forest\n",
    "âœ…âœ… Ráº¥t tá»‘t\n",
    "âœ… Tá»‘t\n",
    "âœ…âœ… Ráº¥t tá»‘t\n",
    "âš ï¸ Trung bÃ¬nh\n",
    "âš¡ Nhanh\n",
    "SVR\n",
    "âœ… Tá»‘t\n",
    "âŒ KÃ©m\n",
    "âœ… Tá»‘t\n",
    "âŒ KÃ©m\n",
    "ğŸ¢ Cháº­m\n",
    "Neural Network\n",
    "âŒ KÃ©m\n",
    "âœ…âœ… Ráº¥t tá»‘t\n",
    "âœ…âœ…âœ… Xuáº¥t sáº¯c\n",
    "âŒ Há»™p Ä‘en\n",
    "ğŸ¢ Cháº­m (náº¿u khÃ´ng cÃ³ GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0601741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.9999\n",
      "Epoch 200, Loss: 0.9384\n",
      "Epoch 400, Loss: 0.0653\n",
      "Epoch 600, Loss: 0.0328\n",
      "Epoch 800, Loss: 0.0318\n",
      "\n",
      "âœ… MSE (Neural Network Regressor tá»± code): 766.04\n",
      "âœ… RÂ²: 0.9628\n",
      "ğŸ” Sklearn MLPRegressor RÂ²: 0.9312\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class SimpleNeuralNetworkRegressor:\n",
    "    def __init__(self, input_size, hidden_size, learning_rate=0.01):\n",
    "        self.lr = learning_rate\n",
    "        # Khá»Ÿi táº¡o trá»ng sá»‘ ngáº«u nhiÃªn\n",
    "        self.W1 = np.random.randn(input_size, hidden_size) * 0.01\n",
    "        self.b1 = np.zeros((1, hidden_size))\n",
    "        self.W2 = np.random.randn(hidden_size, 1) * 0.01  # Ä‘áº§u ra: 1 giÃ¡ trá»‹\n",
    "        self.b2 = np.zeros((1, 1))\n",
    "\n",
    "    def _relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.z1 = np.dot(X, self.W1) + self.b1\n",
    "        self.a1 = self._relu(self.z1)\n",
    "        self.z2 = np.dot(self.a1, self.W2) + self.b2\n",
    "        return self.z2  # KHÃ”NG dÃ¹ng softmax/sigmoid â†’ giá»¯ nguyÃªn giÃ¡ trá»‹ thá»±c\n",
    "\n",
    "    def backward(self, X, y_true, y_pred):\n",
    "        m = X.shape[0]\n",
    "        # Gradient táº¡i Ä‘áº§u ra (vá»›i MSE loss)\n",
    "        dz2 = (2 / m) * (y_pred - y_true)  # Ä‘áº¡o hÃ m cá»§a MSE\n",
    "        dW2 = np.dot(self.a1.T, dz2)\n",
    "        db2 = np.sum(dz2, axis=0, keepdims=True)\n",
    "\n",
    "        # Gradient táº¡i lá»›p áº©n\n",
    "        da1 = np.dot(dz2, self.W2.T)\n",
    "        dz1 = da1 * (self.z1 > 0)  # Ä‘áº¡o hÃ m ReLU\n",
    "        dW1 = np.dot(X.T, dz1)\n",
    "        db1 = np.sum(dz1, axis=0, keepdims=True)\n",
    "\n",
    "        # Cáº­p nháº­t\n",
    "        self.W2 -= self.lr * dW2\n",
    "        self.b2 -= self.lr * db2\n",
    "        self.W1 -= self.lr * dW1\n",
    "        self.b1 -= self.lr * db1\n",
    "\n",
    "    def fit(self, X, y, epochs=1000):\n",
    "        y = y.reshape(-1, 1)  # Ä‘áº£m báº£o shape (n, 1)\n",
    "        for epoch in range(epochs):\n",
    "            y_pred = self.forward(X)\n",
    "            loss = np.mean((y_pred - y) ** 2)  # MSE\n",
    "            self.backward(X, y, y_pred)\n",
    "            if epoch % 200 == 0:\n",
    "                print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.forward(X).flatten()\n",
    "\n",
    "# --- Thá»­ nghiá»‡m ---\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Táº¡o dá»¯ liá»‡u\n",
    "X, y = make_regression(n_samples=500, n_features=10, noise=20, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Chuáº©n hÃ³a (giÃºp máº¡ng há»c á»•n Ä‘á»‹nh)\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "X_train = scaler_X.fit_transform(X_train)\n",
    "X_test = scaler_X.transform(X_test)\n",
    "y_train = scaler_y.fit_transform(y_train.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Huáº¥n luyá»‡n máº¡ng neural há»“i quy tá»± code\n",
    "nn_reg = SimpleNeuralNetworkRegressor(\n",
    "    input_size=10, \n",
    "    hidden_size=16, \n",
    "    learning_rate=0.01\n",
    ")\n",
    "nn_reg.fit(X_train, y_train, epochs=1000)\n",
    "\n",
    "# Dá»± Ä‘oÃ¡n vÃ  hoÃ n ngÆ°á»£c chuáº©n hÃ³a\n",
    "y_pred_scaled = nn_reg.predict(X_test)\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()\n",
    "\n",
    "# ÄÃ¡nh giÃ¡\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"\\nâœ… MSE (Neural Network Regressor tá»± code): {mse:.2f}\")\n",
    "print(f\"âœ… RÂ²: {r2:.4f}\")\n",
    "\n",
    "# So sÃ¡nh vá»›i sklearn MLPRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "sk_nn = MLPRegressor(\n",
    "    hidden_layer_sizes=(16,), \n",
    "    activation='relu', \n",
    "    solver='adam', \n",
    "    max_iter=1000, \n",
    "    random_state=42\n",
    ")\n",
    "sk_nn.fit(X_train, y_train)\n",
    "sk_pred_scaled = sk_nn.predict(X_test)\n",
    "sk_pred = scaler_y.inverse_transform(sk_pred_scaled.reshape(-1, 1)).flatten()\n",
    "sk_r2 = r2_score(y_test, sk_pred)\n",
    "print(f\"ğŸ” Sklearn MLPRegressor RÂ²: {sk_r2:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
