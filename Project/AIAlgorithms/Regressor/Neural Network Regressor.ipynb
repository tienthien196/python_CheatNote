{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "983541e9",
   "metadata": {},
   "source": [
    "— tức là sử dụng mạng neural (Neural Networks) để dự đoán giá trị liên tục, thay vì phân loại.\n",
    "\n",
    "Đây là bước mở đường vào Deep Learning cho hồi quy, và cực kỳ quan trọng trong các bài toán như: dự báo thời tiết, dự đoán giá cổ phiếu, ước lượng năng lượng tiêu thụ, v.v.\n",
    "\n",
    "Mình sẽ trình bày theo đúng phong cách bạn yêu thích:\n",
    "\n",
    "🔹 1. Nguyên lý hoạt động (không công thức nặng!)\n",
    "🎯 Mục tiêu:\n",
    "Dự đoán một số thực (giá nhà, nhiệt độ, doanh thu...) bằng cách học biểu diễn phi tuyến phức tạp từ dữ liệu, thông qua nhiều lớp nơ-ron nhân tạo.\n",
    "\n",
    "🧠 Ý tưởng chính — “Học từ đơn giản đến phức tạp, rồi đưa ra con số”\n",
    "Đầu vào: các đặc trưng (diện tích, số phòng, vị trí…)\n",
    "Các lớp ẩn: học đặc trưng ngày càng trừu tượng\n",
    "Lớp 1: kết hợp tuyến tính → áp hàm kích hoạt (ReLU)\n",
    "Lớp 2: kết hợp kết quả lớp 1 → lại áp ReLU\n",
    "...\n",
    "Đầu ra: một nơ-ron duy nhất, không có hàm kích hoạt phi tuyến (hoặc dùng hàm identity) → ra giá trị thực\n",
    "💡 Khác với phân loại (dùng softmax/sigmoid để ra xác suất),\n",
    "hồi quy bằng mạng neural → lớp cuối cùng là tuyến tính. \n",
    "\n",
    "🔁 Quá trình học:\n",
    "Forward pass: đưa dữ liệu qua mạng → ra dự đoán số thực.\n",
    "Tính lỗi: thường dùng MSE (Mean Squared Error).\n",
    "Backpropagation: lan truyền lỗi ngược → cập nhật trọng số.\n",
    "Lặp lại → mạng ngày càng dự đoán chính xác hơn.\n",
    "✅ Ưu điểm:\n",
    "Mạnh với quan hệ phi tuyến phức tạp.\n",
    "Tự động học đặc trưng — không cần thiết kế tay.\n",
    "Mở rộng tốt: có thể thêm lớp, nơ-ron, hoặc chuyển sang CNN/RNN nếu cần.\n",
    "❌ Hạn chế:\n",
    "Cần nhiều dữ liệu để học tốt.\n",
    "Tốn tài nguyên (GPU, thời gian huấn luyện).\n",
    "Dễ overfit nếu không kiểm soát (dùng dropout, early stopping…).\n",
    "“Hộp đen”: khó giải thích tại sao ra con số đó.\n",
    "\n",
    "\n",
    "🔹 3. Khi nào dùng Neural Network Regressor?\n",
    "Dữ liệu\n",
    "rất lớn\n",
    "(hàng chục nghìn mẫu trở lên)\n",
    "Dữ liệu\n",
    "nhỏ\n",
    "(< 1000 mẫu) → dùng\n",
    "Random Forest\n",
    "hoặc\n",
    "SVR\n",
    "Mối quan hệ\n",
    "phi tuyến cực kỳ phức tạp\n",
    "Mối quan hệ\n",
    "gần tuyến tính\n",
    "→ Linear/Ridge/Lasso đủ\n",
    "Bạn có\n",
    "GPU\n",
    "và\n",
    "thời gian huấn luyện\n",
    "Cần\n",
    "kết quả nhanh, đơn giản\n",
    "Bài toán\n",
    "ảnh, chuỗi, văn bản\n",
    "(khi mở rộng thành CNN/RNN)\n",
    "Dữ liệu\n",
    "bảng đơn giản\n",
    "(Excel-style) → RF thường đủ và giải thích được\n",
    "\n",
    "🎯 So sánh nhanh với các mô hình hồi quy khác:\n",
    "Linear/Ridge/Lasso\n",
    "✅ Tốt\n",
    "✅ Tốt\n",
    "❌ Kém\n",
    "✅ Rất tốt\n",
    "⚡ Rất nhanh\n",
    "Decision Tree\n",
    "✅ Tốt\n",
    "✅ Tốt\n",
    "✅ Tốt\n",
    "✅ Tốt\n",
    "⚡ Nhanh\n",
    "Random Forest\n",
    "✅✅ Rất tốt\n",
    "✅ Tốt\n",
    "✅✅ Rất tốt\n",
    "⚠️ Trung bình\n",
    "⚡ Nhanh\n",
    "SVR\n",
    "✅ Tốt\n",
    "❌ Kém\n",
    "✅ Tốt\n",
    "❌ Kém\n",
    "🐢 Chậm\n",
    "Neural Network\n",
    "❌ Kém\n",
    "✅✅ Rất tốt\n",
    "✅✅✅ Xuất sắc\n",
    "❌ Hộp đen\n",
    "🐢 Chậm (nếu không có GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0601741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.9999\n",
      "Epoch 200, Loss: 0.9384\n",
      "Epoch 400, Loss: 0.0653\n",
      "Epoch 600, Loss: 0.0328\n",
      "Epoch 800, Loss: 0.0318\n",
      "\n",
      "✅ MSE (Neural Network Regressor tự code): 766.04\n",
      "✅ R²: 0.9628\n",
      "🔍 Sklearn MLPRegressor R²: 0.9312\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class SimpleNeuralNetworkRegressor:\n",
    "    def __init__(self, input_size, hidden_size, learning_rate=0.01):\n",
    "        self.lr = learning_rate\n",
    "        # Khởi tạo trọng số ngẫu nhiên\n",
    "        self.W1 = np.random.randn(input_size, hidden_size) * 0.01\n",
    "        self.b1 = np.zeros((1, hidden_size))\n",
    "        self.W2 = np.random.randn(hidden_size, 1) * 0.01  # đầu ra: 1 giá trị\n",
    "        self.b2 = np.zeros((1, 1))\n",
    "\n",
    "    def _relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.z1 = np.dot(X, self.W1) + self.b1\n",
    "        self.a1 = self._relu(self.z1)\n",
    "        self.z2 = np.dot(self.a1, self.W2) + self.b2\n",
    "        return self.z2  # KHÔNG dùng softmax/sigmoid → giữ nguyên giá trị thực\n",
    "\n",
    "    def backward(self, X, y_true, y_pred):\n",
    "        m = X.shape[0]\n",
    "        # Gradient tại đầu ra (với MSE loss)\n",
    "        dz2 = (2 / m) * (y_pred - y_true)  # đạo hàm của MSE\n",
    "        dW2 = np.dot(self.a1.T, dz2)\n",
    "        db2 = np.sum(dz2, axis=0, keepdims=True)\n",
    "\n",
    "        # Gradient tại lớp ẩn\n",
    "        da1 = np.dot(dz2, self.W2.T)\n",
    "        dz1 = da1 * (self.z1 > 0)  # đạo hàm ReLU\n",
    "        dW1 = np.dot(X.T, dz1)\n",
    "        db1 = np.sum(dz1, axis=0, keepdims=True)\n",
    "\n",
    "        # Cập nhật\n",
    "        self.W2 -= self.lr * dW2\n",
    "        self.b2 -= self.lr * db2\n",
    "        self.W1 -= self.lr * dW1\n",
    "        self.b1 -= self.lr * db1\n",
    "\n",
    "    def fit(self, X, y, epochs=1000):\n",
    "        y = y.reshape(-1, 1)  # đảm bảo shape (n, 1)\n",
    "        for epoch in range(epochs):\n",
    "            y_pred = self.forward(X)\n",
    "            loss = np.mean((y_pred - y) ** 2)  # MSE\n",
    "            self.backward(X, y, y_pred)\n",
    "            if epoch % 200 == 0:\n",
    "                print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.forward(X).flatten()\n",
    "\n",
    "# --- Thử nghiệm ---\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Tạo dữ liệu\n",
    "X, y = make_regression(n_samples=500, n_features=10, noise=20, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Chuẩn hóa (giúp mạng học ổn định)\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "X_train = scaler_X.fit_transform(X_train)\n",
    "X_test = scaler_X.transform(X_test)\n",
    "y_train = scaler_y.fit_transform(y_train.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Huấn luyện mạng neural hồi quy tự code\n",
    "nn_reg = SimpleNeuralNetworkRegressor(\n",
    "    input_size=10, \n",
    "    hidden_size=16, \n",
    "    learning_rate=0.01\n",
    ")\n",
    "nn_reg.fit(X_train, y_train, epochs=1000)\n",
    "\n",
    "# Dự đoán và hoàn ngược chuẩn hóa\n",
    "y_pred_scaled = nn_reg.predict(X_test)\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Đánh giá\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"\\n✅ MSE (Neural Network Regressor tự code): {mse:.2f}\")\n",
    "print(f\"✅ R²: {r2:.4f}\")\n",
    "\n",
    "# So sánh với sklearn MLPRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "sk_nn = MLPRegressor(\n",
    "    hidden_layer_sizes=(16,), \n",
    "    activation='relu', \n",
    "    solver='adam', \n",
    "    max_iter=1000, \n",
    "    random_state=42\n",
    ")\n",
    "sk_nn.fit(X_train, y_train)\n",
    "sk_pred_scaled = sk_nn.predict(X_test)\n",
    "sk_pred = scaler_y.inverse_transform(sk_pred_scaled.reshape(-1, 1)).flatten()\n",
    "sk_r2 = r2_score(y_test, sk_pred)\n",
    "print(f\"🔍 Sklearn MLPRegressor R²: {sk_r2:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
