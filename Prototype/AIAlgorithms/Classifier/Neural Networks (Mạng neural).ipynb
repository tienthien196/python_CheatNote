{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbae524f",
   "metadata": {},
   "source": [
    "🔹 1. Nguyên lý hoạt động (không công thức nặng!)\n",
    "🎯 Mục tiêu:\n",
    "Mô phỏng cách não người xử lý thông tin — bằng cách kết nối nhiều \"nơ-ron nhân tạo\" thành mạng, để học biểu diễn phức tạp từ dữ liệu.\n",
    "\n",
    "🧠 Ý tưởng chính — “Học từng lớp, từ đơn giản đến phức tạp”\n",
    "Nơ-ron đơn lẻ ≈ Logistic Regression:\n",
    "→ Nhận đầu vào → kết hợp có trọng số → đưa qua hàm kích hoạt (sigmoid, ReLU...) → ra kết quả.\n",
    "Mạng neural = nhiều lớp nơ-ron xếp chồng:\n",
    "Lớp đầu vào (input): dữ liệu thô (pixel, từ, số...).\n",
    "Lớp ẩn (hidden layers): học đặc trưng ngày càng trừu tượng.\n",
    "Ví dụ ảnh mèo:\n",
    "Lớp 1: phát hiện cạnh, góc\n",
    "Lớp 2: phát hiện mắt, tai\n",
    "Lớp 3: phát hiện “mặt mèo”\n",
    "Lớp đầu ra (output): dự đoán (xác suất các lớp).\n",
    "🔍 Làm sao mạng \"học\"?\n",
    "Forward pass: đưa dữ liệu qua mạng → ra dự đoán.\n",
    "So sánh dự đoán với nhãn thật → tính lỗi (loss).\n",
    "Backpropagation: lan truyền lỗi ngược lại, điều chỉnh trọng số để giảm lỗi.\n",
    "Lặp lại hàng nghìn lần → mạng tự cải thiện.\n",
    "🌟 Không cần nhớ đạo hàm!\n",
    "Chỉ cần hiểu: mạng thử → sai → sửa → thử lại → ngày càng đúng hơn. \n",
    "\n",
    "✅ Ưu điểm:\n",
    "Rất mạnh với dữ liệu phức tạp: ảnh, âm thanh, văn bản.\n",
    "Tự động học đặc trưng — không cần thiết kế tay.\n",
    "Linh hoạt: có thể mở rộng thành CNN, RNN, Transformer...\n",
    "❌ Hạn chế:\n",
    "Cần nhiều dữ liệu để học tốt.\n",
    "Tốn tài nguyên (GPU, thời gian).\n",
    "\"Hộp đen\": khó giải thích tại sao ra kết quả đó.\n",
    "Dễ overfit nếu không kiểm soát.\n",
    " 3. Khi nào dùng Neural Networks?\n",
    "Dữ liệu\n",
    "rất lớn\n",
    "(hàng chục nghìn mẫu trở lên)\n",
    "Dữ liệu\n",
    "rất nhỏ\n",
    "(< 1000 mẫu) → dùng RF/SVM thay\n",
    "Dữ liệu\n",
    "phi cấu trúc\n",
    ": ảnh, âm thanh, văn bản\n",
    "Dữ liệu\n",
    "bảng đơn giản\n",
    "(Excel-style) → RF thường đủ\n",
    "Cần\n",
    "độ chính xác cực cao\n",
    "(computer vision, NLP)\n",
    "Cần\n",
    "giải thích mô hình\n",
    "(y tế, tài chính)\n",
    "Có\n",
    "GPU/tài nguyên tính toán\n",
    "Chỉ có CPU và thời gian hạn chế"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a44bf2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1.0986\n",
      "Epoch 200, Loss: 0.2604\n",
      "Epoch 400, Loss: 0.1234\n",
      "Epoch 600, Loss: 0.0873\n",
      "Epoch 800, Loss: 0.0736\n",
      "\n",
      "✅ Độ chính xác (Neural Network tự code): 100.00%\n",
      "🔍 Sklearn MLP độ chính xác: 97.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class SimpleNeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size, learning_rate=0.1):\n",
    "        self.lr = learning_rate\n",
    "        # Khởi tạo trọng số ngẫu nhiên\n",
    "        self.W1 = np.random.randn(input_size, hidden_size) * 0.01\n",
    "        self.b1 = np.zeros((1, hidden_size))\n",
    "        self.W2 = np.random.randn(hidden_size, output_size) * 0.01\n",
    "        self.b2 = np.zeros((1, output_size))\n",
    "\n",
    "    def _relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def _softmax(self, x):\n",
    "        # Tránh overflow\n",
    "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # Lớp ẩn\n",
    "        self.z1 = np.dot(X, self.W1) + self.b1\n",
    "        self.a1 = self._relu(self.z1)\n",
    "        # Lớp đầu ra\n",
    "        self.z2 = np.dot(self.a1, self.W2) + self.b2\n",
    "        self.a2 = self._softmax(self.z2)\n",
    "        return self.a2\n",
    "\n",
    "    def backward(self, X, y_true, y_pred):\n",
    "        m = X.shape[0]\n",
    "\n",
    "        # Gradient tại lớp đầu ra\n",
    "        dz2 = y_pred - y_true  # với softmax + cross-entropy\n",
    "        dW2 = np.dot(self.a1.T, dz2) / m\n",
    "        db2 = np.sum(dz2, axis=0, keepdims=True) / m\n",
    "\n",
    "        # Gradient tại lớp ẩn\n",
    "        da1 = np.dot(dz2, self.W2.T)\n",
    "        dz1 = da1 * (self.z1 > 0)  # đạo hàm của ReLU\n",
    "        dW1 = np.dot(X.T, dz1) / m\n",
    "        db1 = np.sum(dz1, axis=0, keepdims=True) / m\n",
    "\n",
    "        # Cập nhật trọng số\n",
    "        self.W2 -= self.lr * dW2\n",
    "        self.b2 -= self.lr * db2\n",
    "        self.W1 -= self.lr * dW1\n",
    "        self.b1 -= self.lr * db1\n",
    "\n",
    "    def fit(self, X, y, epochs=1000):\n",
    "        # Chuyển y thành one-hot encoding\n",
    "        n_classes = y.max() + 1\n",
    "        y_onehot = np.eye(n_classes)[y]\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            y_pred = self.forward(X)\n",
    "            loss = -np.mean(np.sum(y_onehot * np.log(y_pred + 1e-9), axis=1))\n",
    "            self.backward(X, y_onehot, y_pred)\n",
    "            if epoch % 200 == 0:\n",
    "                print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = self.forward(X)\n",
    "        return np.argmax(y_pred, axis=1)\n",
    "\n",
    "# --- Thử nghiệm ---\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Chuẩn hóa (giúp mạng học ổn định hơn)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Huấn luyện mạng neural tự code\n",
    "nn_model = SimpleNeuralNetwork(\n",
    "    input_size=4, \n",
    "    hidden_size=8, \n",
    "    output_size=3, \n",
    "    learning_rate=0.1\n",
    ")\n",
    "nn_model.fit(X_train, y_train, epochs=1000)\n",
    "\n",
    "# Dự đoán\n",
    "y_pred = nn_model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\n✅ Độ chính xác (Neural Network tự code): {acc:.2%}\")\n",
    "\n",
    "# So sánh với sklearn MLPClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "sk_nn = MLPClassifier(hidden_layer_sizes=(8,), max_iter=1000, random_state=42)\n",
    "sk_nn.fit(X_train, y_train)\n",
    "sk_acc = sk_nn.score(X_test, y_test)\n",
    "print(f\"🔍 Sklearn MLP độ chính xác: {sk_acc:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
