{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4eb35d23",
   "metadata": {},
   "source": [
    "Đây là hai phiên bản cải tiến của Linear Regression, được thiết kế để giải quyết overfitting và xử lý dữ liệu có nhiều đặc trưng — đặc biệt khi các đặc trưng tương quan cao (đa cộng tuyến) hoặc số đặc trưng > số mẫu.\n",
    "\n",
    "Mình sẽ trình bày theo đúng phong cách quen thuộc:\n",
    "\n",
    "🔹 1. Nguyên lý hoạt động (không công thức nặng!)\n",
    "🎯 Vấn đề với Linear Regression thông thường:\n",
    "Khi có nhiều đặc trưng, hoặc đặc trưng tương quan mạnh, Linear Regression có thể:\n",
    "Overfit (học thuộc nhiễu)\n",
    "Hệ số rất lớn → mô hình không ổn định\n",
    "🧠 Giải pháp: Thêm \"hình phạt\" vào hàm mất mát\n",
    "Cả Ridge và Lasso đều thêm một thành phần phạt vào lỗi MSE, để kìm hãm độ lớn của hệ số.\n",
    "\n",
    "Ridge Regression\n",
    "L2 Regularization\n",
    "Phạt\n",
    "tổng bình phương hệ số\n",
    ":\n",
    "w \n",
    "1\n",
    "2\n",
    "​\n",
    " +w \n",
    "2\n",
    "2\n",
    "​\n",
    " +…\n",
    "Lasso Regression\n",
    "L1 Regularization\n",
    "Phạt\n",
    "tổng giá trị tuyệt đối hệ số\n",
    ":\n",
    "∣w \n",
    "1\n",
    "​\n",
    " ∣+∣w \n",
    "2\n",
    "​\n",
    " ∣+…\n",
    "\n",
    "💡 Hiệu ứng khác biệt:\n",
    "Ridge:\n",
    "Giảm hệ số về gần 0, nhưng không bao giờ = 0.\n",
    "Giúp ổn định mô hình, giảm overfit.\n",
    "Lasso:\n",
    "Ép một số hệ số = 0 → tự động loại bỏ đặc trưng không quan trọng.\n",
    "Vừa chống overfit, vừa chọn đặc trưng (feature selection).\n",
    "🌟 Không cần nhớ công thức!\n",
    "Chỉ cần nhớ: \n",
    "\n",
    "Ridge = làm nhỏ hệ số\n",
    "Lasso = làm nhỏ + loại bỏ đặc trưng\n",
    "✅ Ưu điểm chung:\n",
    "Chống overfit hiệu quả.\n",
    "Ổn định hơn Linear Regression khi dữ liệu có nhiễu.\n",
    "Hoạt động tốt khi số đặc trưng lớn.\n",
    "❌ Hạn chế:\n",
    "Cần chọn tham số phạt (alpha) → dùng cross-validation.\n",
    "Mất tính chất \"giải thích đơn giản\" của Linear Regression (vì hệ số bị co).\n",
    "🔹 3. Khi nào dùng Ridge vs Lasso?\n",
    "Tất cả đặc trưng đều có ích\n",
    ", chỉ muốn\n",
    "giảm overfit\n",
    "✅\n",
    "Ridge\n",
    "Nhiều đặc trưng không quan trọng\n",
    ", muốn\n",
    "tự động chọn đặc trưng\n",
    "✅\n",
    "Lasso\n",
    "Số đặc trưng > số mẫu\n",
    "✅\n",
    "Lasso\n",
    "(Ridge cũng hoạt động, nhưng không chọn đặc trưng)\n",
    "Đặc trưng tương quan mạnh\n",
    "✅\n",
    "Ridge\n",
    "(Lasso có thể chọn ngẫu nhiên 1 trong số chúng)\n",
    "Muốn kết hợp cả hai\n",
    "→ Dùng\n",
    "ElasticNet\n",
    "(kết hợp L1 + L2)\n",
    "🎯 So sánh nhanh với Linear Regression:\n",
    "Chống overfit\n",
    "❌ Không\n",
    "✅ Có\n",
    "✅ Có\n",
    "Chọn đặc trưng\n",
    "❌ Không\n",
    "❌ Không\n",
    "✅ Có\n",
    "Hệ số = 0\n",
    "Hiếm\n",
    "Không\n",
    "✅ Có\n",
    "Ổn định với đặc trưng tương quan\n",
    "Kém\n",
    "✅ Tốt\n",
    "Trung bình\n",
    "Cần chuẩn hóa\n",
    "Nên\n",
    "✅\n",
    "Bắt buộc\n",
    "✅\n",
    "Bắt buộc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62534061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Ridge (tự code) R²: 0.5809065137456728\n",
      "✅ Lasso (tự code) R²: 0.9896262658008363\n",
      "🔍 Sklearn Ridge R²: 0.9893860041183064\n",
      "🔍 Sklearn Lasso R²: 0.989627001327533\n",
      "\n",
      "🌟 Số hệ số = 0 trong Lasso (tự code): 4\n",
      "🌟 Số hệ số = 0 trong Sklearn Lasso: 4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "class RidgeRegressor:\n",
    "    def __init__(self, alpha=1.0, learning_rate=0.01, n_iters=1000):\n",
    "        self.alpha = alpha  # hệ số phạt\n",
    "        self.lr = learning_rate\n",
    "        self.n_iters = n_iters\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        for _ in range(self.n_iters):\n",
    "            y_pred = np.dot(X, self.weights) + self.bias\n",
    "            # Gradient của MSE + L2 penalty\n",
    "            dw = (1/n_samples) * np.dot(X.T, (y_pred - y)) + (2 * self.alpha * self.weights)\n",
    "            db = (1/n_samples) * np.sum(y_pred - y)\n",
    "            self.weights -= self.lr * dw\n",
    "            self.bias -= self.lr * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.dot(X, self.weights) + self.bias\n",
    "\n",
    "\n",
    "class LassoRegressor:\n",
    "    def __init__(self, alpha=1.0, learning_rate=0.01, n_iters=1000):\n",
    "        self.alpha = alpha\n",
    "        self.lr = learning_rate\n",
    "        self.n_iters = n_iters\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def _soft_threshold(self, w, alpha, lr):\n",
    "        \"\"\"Soft thresholding cho L1 penalty\"\"\"\n",
    "        if w > lr * alpha:\n",
    "            return w - lr * alpha\n",
    "        elif w < -lr * alpha:\n",
    "            return w + lr * alpha\n",
    "        else:\n",
    "            return 0.0\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        for _ in range(self.n_iters):\n",
    "            y_pred = np.dot(X, self.weights) + self.bias\n",
    "            # Cập nhật bias (không phạt)\n",
    "            db = (1/n_samples) * np.sum(y_pred - y)\n",
    "            self.bias -= self.lr * db\n",
    "\n",
    "            # Cập nhật weights với soft thresholding\n",
    "            for j in range(n_features):\n",
    "                dw = (1/n_samples) * np.dot(X[:, j], (y_pred - y))\n",
    "                w_new = self.weights[j] - self.lr * dw\n",
    "                self.weights[j] = self._soft_threshold(w_new, self.alpha, self.lr)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.dot(X, self.weights) + self.bias\n",
    "\n",
    "# --- Thử nghiệm ---\n",
    "# Tạo dữ liệu có nhiều đặc trưng, một số không quan trọng\n",
    "X, y = make_regression(n_samples=100, n_features=20, noise=10, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Chuẩn hóa (quan trọng với regularization)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Huấn luyện các mô hình\n",
    "lr = RidgeRegressor(alpha=1.0, learning_rate=0.1, n_iters=2000)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_ridge = lr.predict(X_test)\n",
    "\n",
    "lasso = LassoRegressor(alpha=0.5, learning_rate=0.1, n_iters=2000)\n",
    "lasso.fit(X_train, y_train)\n",
    "y_pred_lasso = lasso.predict(X_test)\n",
    "\n",
    "# So sánh với sklearn\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "sk_ridge = Ridge(alpha=1.0)\n",
    "sk_ridge.fit(X_train, y_train)\n",
    "sk_lasso = Lasso(alpha=0.5, max_iter=2000)\n",
    "sk_lasso.fit(X_train, y_train)\n",
    "\n",
    "# Đánh giá\n",
    "print(\"✅ Ridge (tự code) R²:\", r2_score(y_test, y_pred_ridge))\n",
    "print(\"✅ Lasso (tự code) R²:\", r2_score(y_test, y_pred_lasso))\n",
    "print(\"🔍 Sklearn Ridge R²:\", sk_ridge.score(X_test, y_test))\n",
    "print(\"🔍 Sklearn Lasso R²:\", sk_lasso.score(X_test, y_test))\n",
    "\n",
    "# Xem hệ số Lasso (nhiều hệ số = 0!)\n",
    "print(\"\\n🌟 Số hệ số = 0 trong Lasso (tự code):\", np.sum(np.abs(lasso.weights) < 1e-4))\n",
    "print(\"🌟 Số hệ số = 0 trong Sklearn Lasso:\", np.sum(sk_lasso.coef_ == 0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
